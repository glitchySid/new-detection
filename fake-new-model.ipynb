{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['label', 'text']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pl.read_csv('news_dataset.csv')\n",
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_data = dataset['text']\n",
    "y_train_data = dataset['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = []\n",
    "y_train= []\n",
    "for sentence in x_train_data:\n",
    "    x_train.append(sentence)\n",
    "for labels in y_train_data:\n",
    "    if labels == 'REAL':\n",
    "        y_train.append(1)\n",
    "    else:\n",
    "        y_train.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove newline characters from sentences in x_train\n",
    "x_train_cleaned = []\n",
    "for sentence in x_train:\n",
    "    if sentence is not None:\n",
    "        x_train_cleaned.append(sentence.replace('\\n', ' '))\n",
    "    else:\n",
    "        x_train_cleaned.append('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Republic Poll, a fake Twitter account imitating the Arnab Goswami-led Republic TV, is angering netizens with its controversial polls as Twitter users including journalists mistake it for the channel\\'s official account.    The fake account (@RepublicPoll) uses a logo very similar to Republic TV\\'s logo and does not mention in its bio whether it is related to Republic TV or if it is a fan account. Twitter\\'s rules require that a fan account or parody account should indicate the same.  Also Read:Did Nita Ambani Ask For Support For CAA?      Siddharth Varadarajan, founding editor of The Wire.in, in a now deleted tweet, had shared a screenshot of a poll by the fake account claiming it was a \\'poll run by a \"nationalistic\" media house\\'.  This is hilarious. Despite the desperate phrasing of the question, this poll run by a \"nationalist\" media house has ended up condemning the innocent, \"minority in JNU\" ABVP. pic.twitter.com/gQGtzFEU26 — Siddharth (@svaradarajan) January 7, 2020          After several Twitter users pointed out that the account was fake Varadarajan later clarified that it was a parody account.  So I am told @republicpoll is a parody account. Which kinda makes sense since Republic TV is a parody news channel! — Siddharth (@svaradarajan) January 7, 2020      \"Nudge\" In polling via carefully placed words like \\'goons\\' and \\'minority in JNU\\' doesn\\'t seem to work. pic.twitter.com/Vfa2dfxVST — Andy Mukherjee (@andymukherjee70) January 6, 2020  Click here to view an archive.  We compared the official logo of Republic TV with the logo used by the fake Twitter account and found that they do not match. The fake account is not verified and created on April 1, 2019, whereas Republic TV official Twitter account was created in December 2016.        Republic TV (@Republic) has been conducting polls on its official Twitter handle.  #TukdeGangSpotted | Is there a pattern to the protests? — Republic (@republic) January 6, 2020  The fake account has been regularly tweeting these polls, and while writing the article, it has 244 tweets, all of which are controversial polls. It currently has 2,671 Followers, whereas the official Republic TV Twitter account has 769 lakh followers and is not following it.  Loaded Polls By \\'@RepublicPoll\\'    The fake account has been tweeting polls on recent issues framing it with an ideologically right wing slant. Click here to view an archive.  Click here to view an archive.  #SwaraBhaskar has no any valid document.  Then the Question that arises is....    How this lately Anarkali travel all around the World without Passport ??? — Republic Poll (@RepublicPoll) January 5, 2020  Click here to view an archive.  Several Twitter users have taken on the account for its polls. The fake account has also deleted polls that are not favorable to it.  Despite your best attempts at trying to sway the votes by calling JNU students goons and ABVP a minority, people\\'s votes show who the culprit is and who the chutiya is. Ghar jao kutton. pic.twitter.com/8Of3ejMt3p — Rutuja/ऋतुजा🇮🇳 (@HavaldarShinde) January 6, 2020                '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_cleaned[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1.]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 50  # Maximum sequence length\n",
    "vocab_size = 10000  # Number of words to consider\n",
    "embedding_dim = 128  # Embedding dimension\n",
    "lstm_units = 64 \n",
    "\n",
    "tokenizer = Tokenizer(num_words=vocab_size, oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(x_train_cleaned)\n",
    "sequences = tokenizer.texts_to_sequences(x_train_cleaned)\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_len)\n",
    "padded_sequences = np.array(padded_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data, validation_data, training_labels, validation_labels = train_test_split(padded_sequences, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/machineL/lib/python3.9/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n",
      "2024-06-18 15:23:04.890438: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1\n",
      "2024-06-18 15:23:04.890469: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 8.00 GB\n",
      "2024-06-18 15:23:04.890479: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 2.67 GB\n",
      "2024-06-18 15:23:04.890772: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-06-18 15:23:04.890795: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2024-06-18 15:23:05.753893: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 52ms/step - accuracy: 0.7970 - loss: 0.4773 - val_accuracy: 0.9665 - val_loss: 0.0901\n",
      "Epoch 2/3\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9836 - loss: 0.0523 - val_accuracy: 0.9692 - val_loss: 0.0900\n",
      "Epoch 3/3\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9971 - loss: 0.0090 - val_accuracy: 0.9611 - val_loss: 0.1921\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x34be79d90>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "  Embedding(vocab_size, embedding_dim, input_length=max_len),\n",
    "  LSTM(lstm_units),\n",
    "  Dense(128, activation='relu'),\n",
    "  Dense(2, activation='sigmoid')  # Output layer for binary classification\n",
    "])\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(training_data, training_labels, epochs=3, validation_data=(validation_data, validation_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 471ms/step\n",
      "News is Real\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "new_text = \"Mumbai hoarding collapse: 14 killed; traffic jams in Ghatkopar | Latest updates\"  # Replace with your new text\n",
    "new_sequence = tokenizer.texts_to_sequences([new_text])\n",
    "padded_new_sequence = pad_sequences(new_sequence, maxlen=max_len)\n",
    "prediction = model.predict(padded_new_sequence)\n",
    "if np.argmax(prediction)==1:\n",
    "    print(\"News is Real\")\n",
    "else:\n",
    "    print(\"News is fake\")\n",
    "print(np.argmax(prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_json = tokenizer.to_json()\n",
    "with open('tokenizer.json', 'w', encoding='utf-8') as f:\n",
    "    f.write(json.dumps(tokenizer_json, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('newsdetection.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import json\n",
    "from tensorflow.keras.preprocessing.text import tokenizer_from_json\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tokenizer.json', 'r') as t:\n",
    "    data = json.load(t)\n",
    "    tokenizer = tokenizer_from_json(data)\n",
    "model = tf.keras.models.load_model('newsdetection.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step\n",
      "News is Real\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-18 15:30:33.727329: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "new_text = \"Mumbai hoarding collapse: 14 killed; traffic jams in Ghatkopar | Latest updates\"  # Replace with your new text\n",
    "new_sequence = tokenizer.texts_to_sequences([new_text])\n",
    "padded_new_sequence = pad_sequences(new_sequence, maxlen=50)\n",
    "prediction = model.predict(padded_new_sequence)\n",
    "if np.argmax(prediction)==1:\n",
    "    print(\"News is Real\")\n",
    "else:\n",
    "    print(\"News is fake\")\n",
    "print(np.argmax(prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machineL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
